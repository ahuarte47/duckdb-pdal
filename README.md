# DuckDB Point Cloud Extension

ğŸš§ WORK IN PROGRESS ğŸš§

## What is this?

This is an extension for DuckDB for manipulating point cloud data using SQL.

The extension is built on top of [PDAL (Point Data Abstraction Library)](https://pdal.io/), a C++ library allowing users to read, write, and process point cloud data directly within DuckDB using SQL queries.

## How do I get it?

### (TODO) Loading from community

The DuckDB **Point Cloud Extension** is available as a signed [community extension](https://duckdb.org/community_extensions/list_of_extensions).
See more details on its [DuckDB CE web page](https://duckdb.org/community_extensions/extensions/pdal.html).

To install and load it, you can run the following SQL commands in DuckDB:

```sql
INSTALL pdal FROM community;
LOAD pdal;
```

### Building from source

This extension is based on the [DuckDB extension template](https://github.com/duckdb/extension-template).

## Example Usage

You can use the extension to read point cloud data from various formats (e.g., LAS, LAZ, etc.) and perform spatial queries on them.

First, make sure to load the extension in your DuckDB session.

+ ### PDAL_Drivers

    Returns the list of supported stage types of a PDAL Pipeline.

	The stages of a PDAL Pipeline are divided into Readers, Filters and Writers: https://pdal.io/en/stable/stages/stages.html

    ```sql
    SELECT * FROM PDAL_Drivers();

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            name             â”‚                                     description                                 â”‚  category â”‚
    â”‚           varchar           â”‚                                       varchar                                   â”‚  varchar  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ filters.approximatecoplanar â”‚ Estimates the planarity of a neighborhood of points using eigenvalues.          â”‚  filters  â”‚
    â”‚ filters.assign              â”‚ Assign values for a dimension range to a specified value.                       â”‚  filters  â”‚
    â”‚ filters.chipper             â”‚ Organize points into spatially contiguous, squarish, and non-overlapping chips. â”‚  filters  â”‚
    â”‚ filters.cluster             â”‚ Extract and label clusters using Euclidean distance.                            â”‚  filters  â”‚
    â”‚ filters.colorinterp         â”‚ Assigns RGB colors based on a dimension and a ramp                              â”‚  filters  â”‚
    â”‚ filters.colorization        â”‚ Fetch and assign RGB color information from a GDAL-readable datasource.         â”‚  filters  â”‚
    â”‚ filters.crop                â”‚ Filter points inside or outside a bounding box or a polygon                     â”‚  filters  â”‚
    â”‚ filters.csf                 â”‚ Cloth Simulation Filter (Zhang et al., 2016)                                    â”‚  filters  â”‚
    â”‚ filters.dbscan              â”‚ DBSCAN Clustering.                                                              â”‚  filters  â”‚
    â”‚ filters.decimation          â”‚ Rank decimation filter. Keep every Nth point                                    â”‚  filters  â”‚
    â”‚ filters.delaunay            â”‚ Perform Delaunay triangulation of a pointcloud                                  â”‚  filters  â”‚
    â”‚ filters.dem                 â”‚ Filter points about an elevation surface                                        â”‚  filters  â”‚
    â”‚ filters.divider             â”‚ Divide points into approximately equal sized groups based on a simple scheme    â”‚  filters  â”‚
    â”‚ filters.eigenvalues         â”‚ Returns the eigenvalues for a given point, based on its k-nearest neighbors.    â”‚  filters  â”‚
    â”‚ filters.elm                 â”‚ Marks low points as noise.                                                      â”‚  filters  â”‚
    â”‚ filters.estimaterank        â”‚ Computes the rank of a neighborhood of points.                                  â”‚  filters  â”‚
    â”‚ filters.expression          â”‚ Pass only points given an expression                                            â”‚  filters  â”‚
    â”‚ filters.expressionstats     â”‚ Accumulate count statistics for a given dimension for an array of expressions   â”‚  filters  â”‚
    â”‚ filters.faceraster          â”‚ Face Raster Filter                                                              â”‚  filters  â”‚
    â”‚      Â·                      â”‚      Â·                                                                          â”‚     Â·     â”‚
    â”‚      Â·                      â”‚      Â·                                                                          â”‚     Â·     â”‚
    â”‚      Â·                      â”‚      Â·                                                                          â”‚     Â·     â”‚
    â”‚ readers.slpk                â”‚ SLPK Reader                                                                     â”‚  readers  â”‚
    â”‚ readers.smrmsg              â”‚ SBET smrmsg Reader                                                              â”‚  readers  â”‚
    â”‚ readers.stac                â”‚ STAC Reader                                                                     â”‚  readers  â”‚
    â”‚ readers.terrasolid          â”‚ TerraSolid Reader                                                               â”‚  readers  â”‚
    â”‚ readers.text                â”‚ Text Reader                                                                     â”‚  readers  â”‚
    â”‚ readers.tindex              â”‚ TileIndex Reader                                                                â”‚  readers  â”‚
    â”‚ writers.copc                â”‚ COPC Writer                                                                     â”‚  writers  â”‚
    â”‚ writers.ept_addon           â”‚ EPT Writer                                                                      â”‚  writers  â”‚
    â”‚ writers.fbi                 â”‚ FBI Writer                                                                      â”‚  writers  â”‚
    â”‚ writers.gdal                â”‚ Write a point cloud as a GDAL raster.                                           â”‚  writers  â”‚
    â”‚ writers.gltf                â”‚ Gltf Writer                                                                     â”‚  writers  â”‚
    â”‚ writers.las                 â”‚ ASPRS LAS 1.0 - 1.4 writer                                                      â”‚  writers  â”‚
    â”‚ writers.ogr                 â”‚ Write a point cloud as a set of OGR points/multipoints                          â”‚  writers  â”‚
    â”‚ writers.pcd                 â”‚ Write data in the Point Cloud Library (PCL) format.                             â”‚  writers  â”‚
    â”‚ writers.ply                 â”‚ ply writer                                                                      â”‚  writers  â”‚
    â”‚ writers.raster              â”‚ Write a raster.                                                                 â”‚  writers  â”‚
    â”‚ writers.sbet                â”‚ SBET Writer                                                                     â”‚  writers  â”‚
    â”‚ writers.text                â”‚ Text Writer                                                                     â”‚  writers  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 119 rows (40 shown)                                                                                             3 columns â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

+ ### PDAL_Read

    You can read point cloud data from a file with:

    ```sql
    SELECT
        *
    FROM
        PDAL_Read('path/to/your/pointcloud.las')
    ;

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     X     â”‚     Y     â”‚   Z    â”‚       â”‚
    â”‚   double  â”‚   double  â”‚ double â”‚  ...  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 637177.98 â”‚ 849393.95 â”‚ 411.19 â”‚  ...  â”‚
    â”‚ 637177.30 â”‚ 849396.95 â”‚ 411.25 â”‚  ...  â”‚
    â”‚ 637176.34 â”‚ 849400.84 â”‚ 411.01 â”‚  ...  â”‚
    â”‚ 637175.45 â”‚ 849404.62 â”‚ 410.99 â”‚  ...  â”‚
    â”‚ 637174.33 â”‚ 849407.37 â”‚ 411.38 â”‚  ...  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

    Setting options is also possible. For example, to read a subset of points starting from index 10:

    ```sql
    SELECT
        X, Y, Z, Red, Green, Blue
    FROM
        PDAL_Read('./test/data/autzen_trim.laz', options => MAP {'start': 10})
    ;

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     X     â”‚    Y      â”‚    Z    â”‚  Red   â”‚ Green  â”‚  Blue  â”‚
    â”‚   double  â”‚  double   â”‚  double â”‚ uint16 â”‚ uint16 â”‚ uint16 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 637173.82 â”‚ 849395.08 â”‚   11.22 â”‚     79 â”‚     94 â”‚     88 â”‚
    â”‚ 637171.38 â”‚ 849403.41 â”‚  411.15 â”‚     78 â”‚     95 â”‚     90 â”‚
    â”‚ 637172.27 â”‚ 849399.57 â”‚  411.22 â”‚     80 â”‚     94 â”‚     89 â”‚
    â”‚ 637173.87 â”‚ 849392.61 â”‚  411.12 â”‚     77 â”‚     93 â”‚     86 â”‚
    â”‚ 637176.11 â”‚ 849383.07 â”‚  411.29 â”‚     80 â”‚    100 â”‚     90 â”‚
    â”‚     Â·     â”‚     Â·     â”‚     Â·   â”‚      Â· â”‚      Â· â”‚      Â· â”‚
    â”‚     Â·     â”‚     Â·     â”‚     Â·   â”‚      Â· â”‚      Â· â”‚      Â· â”‚
    â”‚     Â·     â”‚     Â·     â”‚     Â·   â”‚      Â· â”‚      Â· â”‚      Â· â”‚
    â”‚ 637173.82 â”‚ 849395.08 â”‚  411.22 â”‚     79 â”‚     94 â”‚     88 â”‚
    â”‚ 637173.82 â”‚ 849395.08 â”‚  411.22 â”‚     79 â”‚     94 â”‚     88 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 110000 rows (40 shown)                           6 columns â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

+ ### PDAL_Info

    To get information about the point cloud file without reading all the data, you can use the `PDAL_Info` function.

    For example:

    ```sql
    SELECT
        *
    FROM
        PDAL_Info('./test/data/autzen_trim.la*')
    ;

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      file_name       â”‚ point_count â”‚   min_x   â”‚  min_y    â”‚ min_z  â”‚ â€¦ â”‚ offset_x â”‚ offset_y â”‚ offset_z â”‚
    â”‚       varchar        â”‚   uint64    â”‚  double   â”‚ double    â”‚ double â”‚   â”‚  double  â”‚  double  â”‚  double  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ ./test/data/autzenâ€¦  â”‚      110000 â”‚ 636001.76 â”‚ 848935.20 â”‚ 406.26 â”‚ â€¦ â”‚      0.0 â”‚      0.0 â”‚      0.0 â”‚
    â”‚ ./test/data/autzenâ€¦  â”‚      110000 â”‚ 636001.76 â”‚ 848935.20 â”‚ 406.26 â”‚ â€¦ â”‚      0.0 â”‚      0.0 â”‚      0.0 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ 2 rows                                                                             32 columns (10 shown) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

+ ### PDAL_Pipeline

    You could use the `PDAL_Pipeline` function to run a PDAL pipeline before getting the data:

    ```sql
    SELECT
        COUNT(*)
    FROM
        PDAL_pipeline('./test/data/autzen_trim.las', './test/data/autzen-pipeline.json')
    ;

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ count_star() â”‚
    â”‚    int64     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚     100      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

    The pipeline file can contain any valid PDAL pipeline definition. See the [PDAL documentation](https://pdal.io/en/stable/pipeline.html) for more details.

    For example, the following pipeline returns only the last 100 points:

    ```json
    {
        "pipeline": [
            {
                "type": "filters.tail",
                "count": 100
            }
        ]
    }
    ```

### Supported Functions and Documentation

The full list of functions and their documentation is available in the [function reference](docs/functions.md)

## How do I build it?

### Dependencies

You need a recent version of CMake (3.5) and a C++14 compatible compiler.

We also highly recommend that you install [Ninja](https://ninja-build.org) which you can select when building by setting the `GEN=ninja` environment variable.
```
git clone --recurse-submodules https://github.com/ahuarte47/duckdb-pdal
cd duckdb-pdal
make release
```

You can then invoke the built DuckDB (with the extension statically linked)
```
./build/release/duckdb
```

Please see the Makefile for more options, or the extension template documentation for more details.

### Running the tests

Different tests can be created for DuckDB extensions. The primary way of testing DuckDB extensions should be the SQL tests in `./test/sql`. These SQL tests can be run using:

```sh
make test
```

### Installing the deployed binaries

To install your extension binaries from S3, you will need to do two things. Firstly, DuckDB should be launched with the
`allow_unsigned_extensions` option set to true. How to set this will depend on the client you're using. Some examples:

CLI:
```shell
duckdb -unsigned
```

Python:
```python
con = duckdb.connect(':memory:', config={'allow_unsigned_extensions' : 'true'})
```

NodeJS:
```js
db = new duckdb.Database(':memory:', {"allow_unsigned_extensions": "true"});
```

Secondly, you will need to set the repository endpoint in DuckDB to the HTTP url of your bucket + version of the extension
you want to install. To do this run the following SQL query in DuckDB:
```sql
SET custom_extension_repository='bucket.s3.eu-west-1.amazonaws.com/<your_extension_name>/latest';
```
Note that the `/latest` path will allow you to install the latest extension version available for your current version of
DuckDB. To specify a specific version, you can pass the version instead.

After running these steps, you can install and load your extension using the regular INSTALL/LOAD commands in DuckDB:
```sql
INSTALL pdal;
LOAD pdal;
```

Enjoy!
